{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed on: 2020-06-03 23:06:25.571356\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import ast\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from bert_serving.client import BertClient\n",
    "\n",
    "# This parameter is set on server\n",
    "MAX_SEQUENCE_LEN = 25\n",
    "bc = BertClient()\n",
    "\n",
    "# nltk.download('punkt')\n",
    "\n",
    "def print_completion_time():\n",
    "    print(\"\\nCompleted on: \" + str(datetime.now()))\n",
    "\n",
    "\n",
    "def load_json_file(filename: str) -> dict:\n",
    "    with open(filename, 'r', encoding='utf8') as cve_import_file:\n",
    "        return json.load(cve_import_file)\n",
    "\n",
    "\n",
    "def jprint(json_to_print: dict):\n",
    "    print('\\n' + json.dumps(json_to_print, indent=2))\n",
    "\n",
    "\n",
    "def find_cpe23uri_in_dict(input: dict):\n",
    "    \"\"\"\n",
    "    Recursively retrieve all identifiers of affected software (cpe32uri) from a dict.\n",
    "\n",
    "    Example cpe32uri: cpe:2.3:a:microsoft:.net_framework:1.1:sp1:*:*:*:*:*:*\n",
    "\n",
    "    :param input: NVD database JSON dump.\n",
    "    :return: list of exctracted cpe32uris, if any. None otherwise.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "\n",
    "    if isinstance(input, dict):\n",
    "        if 'cpe23Uri' in input and 'vulnerable' in input and input['vulnerable'] == True:\n",
    "            output.append(input['cpe23Uri'])\n",
    "\n",
    "        else:\n",
    "\n",
    "            for key, value in input.items():\n",
    "                result = find_cpe23uri_in_dict(value)\n",
    "\n",
    "                if result:\n",
    "                    for item in result:\n",
    "                        output.append(item)\n",
    "                        # print(item)\n",
    "\n",
    "    elif isinstance(input, list):\n",
    "        for listitem in input:\n",
    "            result = find_cpe23uri_in_dict(listitem)\n",
    "\n",
    "            if result:\n",
    "                for resultitem in result:\n",
    "                    output.append(resultitem)\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def save_cpe32uri_raw(cve_list: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Save all cpe32uri strings to dict\n",
    "\n",
    "    :param cve_list: CVE list, as imported from NVD json file.\n",
    "    :return: Dictionary mapping vulnerability strings to CVE numbers. Structure:\n",
    "        'cve-id1':\n",
    "            {'vulnerable_config_raw':\n",
    "                ['cpe32uri_1', 'cpe32uri_2', 'cpe32uri_3', ...]\n",
    "            }\n",
    "        'cve-id2':\n",
    "            ...\n",
    "    \"\"\"\n",
    "    print(\"Saving cpe32uris.\")\n",
    "\n",
    "    cve_config_list = {}\n",
    "    for cve in cve_list['CVE_Items']:\n",
    "\n",
    "        vulnerable_stuff = []\n",
    "        for node in cve['configurations']['nodes']:\n",
    "            for item in find_cpe23uri_in_dict(node):\n",
    "                vulnerable_stuff.append(item)\n",
    "\n",
    "        cve_id = cve['cve']['CVE_data_meta']['ID']\n",
    "\n",
    "        cve_config_list[cve_id] ={'vulnerable_config_raw' : vulnerable_stuff}\n",
    "\n",
    "    return cve_config_list\n",
    "\n",
    "\n",
    "def filter_vendor_and_software(cve_config_raw: list) -> dict:\n",
    "    \"\"\"\n",
    "    Filter out vendor and product from dictionary with cpe32uris and count different affected versions.\n",
    "\n",
    "    :param cve_config_raw: mapping of cpe32uri to cve-id numbers. Output of 'save_cpe32uri_raw`\n",
    "\n",
    "    :return: Ammended input dictionary with filtered counts.\n",
    "    \"\"\"\n",
    "    # print(\"Filtering out vendors and software.\")\n",
    "\n",
    "    config_counts = {}\n",
    "    for config in cve_config_raw:\n",
    "\n",
    "        split_config = config.split(':')\n",
    "        config_name = split_config[3] + ' ' + split_config[4]\n",
    "\n",
    "        if config_name not in config_counts:\n",
    "            config_counts[config_name] = 1\n",
    "        else:\n",
    "            config_counts[config_name] += 1\n",
    "\n",
    "    return config_counts\n",
    "\n",
    "\n",
    "def split_long_sentences(long_sentences: list) -> list:\n",
    "    \"\"\"\n",
    "    Take sentences that are longer than parameter MAX_SEQUENCE_LEN and split them into\n",
    "    shorter chunks as necessary.\n",
    "\n",
    "    :param long_sentences: list of sentences, some of which may be too long\n",
    "    :return: changed list of sentences, where all sentences are of good length. Order of the words of the input\n",
    "    is preserved.\n",
    "    \"\"\"\n",
    "\n",
    "    problem_sentences = {}\n",
    "    for index, sentence in enumerate(long_sentences):\n",
    "        words = re.findall(r'\\w+', sentence)\n",
    "\n",
    "        if len(words) > MAX_SEQUENCE_LEN:\n",
    "            problem_sentences[index] = []\n",
    "\n",
    "            while len(words) > MAX_SEQUENCE_LEN:\n",
    "                problem_sentences[index].append(' '.join(words[:MAX_SEQUENCE_LEN]))\n",
    "                words = words[MAX_SEQUENCE_LEN:]\n",
    "\n",
    "            problem_sentences[index].append(' '.join(words))\n",
    "\n",
    "    if len(problem_sentences.keys()) > 0:\n",
    "\n",
    "        order = sorted(list(problem_sentences.keys()), reverse=True)\n",
    "\n",
    "        for index in order:\n",
    "            long_sentences.pop(index)\n",
    "            for short_sentence in reversed(problem_sentences[index]):\n",
    "                long_sentences.insert(index, short_sentence)\n",
    "\n",
    "    return long_sentences\n",
    "\n",
    "\n",
    "def embed_post(post_text: str):\n",
    "    \"\"\"\n",
    "    Embed post text into BERT embeddings. Post text is first split into sentences of maximum length equal or\n",
    "    less than MAX_SENTENCE_LEN. Then individual embedding of length 768 is obtained for each word. Every sentence\n",
    "    is padded with 0 until MAX_SENTENCE_LEN is reached.\n",
    "\n",
    "    :param post_text: raw post text from forum\n",
    "    :return: numpy.ndarray with dimensions [number of sentences][MAX_SENTENCE_LEN][768]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    post_text = post_text.replace('\\n', ' ').replace('\\t', ' ')\n",
    "\n",
    "    sentences = nltk.tokenize.sent_tokenize(post_text)\n",
    "    sentences = split_long_sentences(sentences)\n",
    "\n",
    "    # result = bc.encode(sentences, show_tokens=True)\n",
    "    encoded_sentences = bc.encode(sentences, show_tokens=False)\n",
    "\n",
    "    return encoded_sentences\n",
    "\n",
    "\n",
    "print_completion_time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create positive examples by combining posts with CVE ids from the same time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "cve\n",
      "configurations\n",
      "impact\n",
      "publishedDate\n",
      "lastModifiedDate\n",
      "id\n",
      "                       date  \\\n",
      "0 2016-01-13 05:59:00+00:00   \n",
      "1 2016-01-13 05:59:00+00:00   \n",
      "2 2016-01-13 05:59:00+00:00   \n",
      "3 2016-01-13 05:59:00+00:00   \n",
      "4 2016-01-13 05:59:00+00:00   \n",
      "\n",
      "                                                 cve  \\\n",
      "0  {'data_type': 'CVE', 'data_format': 'MITRE', '...   \n",
      "1  {'data_type': 'CVE', 'data_format': 'MITRE', '...   \n",
      "2  {'data_type': 'CVE', 'data_format': 'MITRE', '...   \n",
      "3  {'data_type': 'CVE', 'data_format': 'MITRE', '...   \n",
      "4  {'data_type': 'CVE', 'data_format': 'MITRE', '...   \n",
      "\n",
      "                                      configurations  \\\n",
      "0  {'CVE_data_version': '4.0', 'nodes': [{'operat...   \n",
      "1  {'CVE_data_version': '4.0', 'nodes': [{'operat...   \n",
      "2  {'CVE_data_version': '4.0', 'nodes': [{'operat...   \n",
      "3  {'CVE_data_version': '4.0', 'nodes': [{'operat...   \n",
      "4  {'CVE_data_version': '4.0', 'nodes': [{'operat...   \n",
      "\n",
      "                                              impact      publishedDate  \\\n",
      "0  {'baseMetricV3': {'cvssV3': {'version': '3.0',...  2016-01-13T05:59Z   \n",
      "1  {'baseMetricV3': {'cvssV3': {'version': '3.0',...  2016-01-13T05:59Z   \n",
      "2  {'baseMetricV3': {'cvssV3': {'version': '3.0',...  2016-01-13T05:59Z   \n",
      "3  {'baseMetricV3': {'cvssV3': {'version': '3.0',...  2016-01-13T05:59Z   \n",
      "4  {'baseMetricV3': {'cvssV3': {'version': '3.0',...  2016-01-13T05:59Z   \n",
      "\n",
      "    lastModifiedDate             id  \n",
      "0  2018-10-12T22:10Z  CVE-2016-0003  \n",
      "1  2018-10-12T22:10Z  CVE-2016-0005  \n",
      "2  2019-05-17T20:08Z  CVE-2016-0006  \n",
      "3  2019-05-17T20:17Z  CVE-2016-0007  \n",
      "4  2019-05-15T19:28Z  CVE-2016-0008  \n",
      "                       date  \\\n",
      "0 2016-01-13 05:59:00+00:00   \n",
      "1 2016-01-13 05:59:00+00:00   \n",
      "2 2016-01-13 05:59:00+00:00   \n",
      "3 2016-01-13 05:59:00+00:00   \n",
      "4 2016-01-13 05:59:00+00:00   \n",
      "\n",
      "                                                 cve  \\\n",
      "0  {'data_type': 'CVE', 'data_format': 'MITRE', '...   \n",
      "1  {'data_type': 'CVE', 'data_format': 'MITRE', '...   \n",
      "2  {'data_type': 'CVE', 'data_format': 'MITRE', '...   \n",
      "3  {'data_type': 'CVE', 'data_format': 'MITRE', '...   \n",
      "4  {'data_type': 'CVE', 'data_format': 'MITRE', '...   \n",
      "\n",
      "                                      configurations  \\\n",
      "0  {'CVE_data_version': '4.0', 'nodes': [{'operat...   \n",
      "1  {'CVE_data_version': '4.0', 'nodes': [{'operat...   \n",
      "2  {'CVE_data_version': '4.0', 'nodes': [{'operat...   \n",
      "3  {'CVE_data_version': '4.0', 'nodes': [{'operat...   \n",
      "4  {'CVE_data_version': '4.0', 'nodes': [{'operat...   \n",
      "\n",
      "                                              impact      publishedDate  \\\n",
      "0  {'baseMetricV3': {'cvssV3': {'version': '3.0',...  2016-01-13T05:59Z   \n",
      "1  {'baseMetricV3': {'cvssV3': {'version': '3.0',...  2016-01-13T05:59Z   \n",
      "2  {'baseMetricV3': {'cvssV3': {'version': '3.0',...  2016-01-13T05:59Z   \n",
      "3  {'baseMetricV3': {'cvssV3': {'version': '3.0',...  2016-01-13T05:59Z   \n",
      "4  {'baseMetricV3': {'cvssV3': {'version': '3.0',...  2016-01-13T05:59Z   \n",
      "\n",
      "    lastModifiedDate             id  week_no  \\\n",
      "0  2018-10-12T22:10Z  CVE-2016-0003        2   \n",
      "1  2018-10-12T22:10Z  CVE-2016-0005        2   \n",
      "2  2019-05-17T20:08Z  CVE-2016-0006        2   \n",
      "3  2019-05-17T20:17Z  CVE-2016-0007        2   \n",
      "4  2019-05-15T19:28Z  CVE-2016-0008        2   \n",
      "\n",
      "                                          vul-target  \n",
      "0                                   [microsoft edge]  \n",
      "1                      [microsoft internet_explorer]  \n",
      "2  [microsoft windows_10, microsoft windows_7, mi...  \n",
      "3  [microsoft windows_10, microsoft windows_7, mi...  \n",
      "4  [microsoft windows_7, microsoft windows_8, mic...  \n"
     ]
    }
   ],
   "source": [
    "with open('/datadrive/train-data/series1/top50vuls.json', 'r', encoding='utf8') as file:\n",
    "    top_vulnerabilities = json.load(file)\n",
    "\n",
    "df_cve = pd.read_csv('/datadrive/train-data/2016_filtered.csv')\n",
    "\n",
    "df_cve['date'] = pd.to_datetime(df_cve['date'], utc=True, infer_datetime_format=True)\n",
    "\n",
    "# # df_cve['vul-']\n",
    "for col in df_cve.columns:\n",
    "    print(col)\n",
    "print(df_cve.head(5))\n",
    "\n",
    "df_cve['week_no'] = df_cve['date'].apply(lambda x: datetime.date(x).isocalendar()[1])\n",
    "\n",
    "df_cve['vul-target'] = df_cve['configurations'].apply(lambda x: list(\n",
    "    filter_vendor_and_software(find_cpe23uri_in_dict(ast.literal_eval(x))).keys()))\n",
    "\n",
    "# print(df_cve.head(5))\n",
    "print_completion_time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed on: 2020-06-03 22:04:42.861932\n"
     ]
    }
   ],
   "source": [
    "def encode_vulnerabilities(input: list) -> list:\n",
    "    output = []\n",
    "    for vul in top_vulnerabilities:\n",
    "        if vul in input:\n",
    "            output.append(1)\n",
    "        else:\n",
    "            output.append(0)\n",
    "\n",
    "    return output\n",
    "\n",
    "df_cve['one-hot'] = df_cve['vul-target'].apply(lambda x: encode_vulnerabilities(x))\n",
    "\n",
    "print_completion_time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input = [\"Python offers a function called translate() that will map one set of characters to another.\",\n",
    "         \"We can use the function maketrans() to create a mapping table.\",\n",
    "         \"We can create an empty mapping table, but the third argument of this function allows us to list all of the characters to remove during the translation process.\",\n",
    "         \"For example:\",\n",
    "         \"table = str.maketrans('', '', string.punctuation)\\n1\\ntable = str.maketrans('', '', string.punctuation)\\n\",\n",
    "         \"We can put all of this together, load the text file, split it into words by white space, then translate each word to remove the punctuation.\"\n",
    "]\n",
    "\n",
    "paragraph_input = 'A Distributed Denial of Service (DDoS) attack employs multiple compromised'+\\\n",
    "                  ' systems to interrupt or suspend services of a host connected to the Internet '+\\\n",
    "                  '[Carl et al., 2006]. Victims are often high-profile web servers such as banks or '+\\\n",
    "                  'credit card payment gateways, and therefore a single attack may cause considerable '+\\\n",
    "                  'loss [Matthews, 2014]. DDoS attacks are difficult to detect and predict [Bleakley '+\\\n",
    "                  'and Vert, 2011]. Traditionally, the aim of a DDoS detection system is to detect '+\\\n",
    "                  'and distinguish malicious packet traffic from legitimate traffic [Mirkovic and Reiher, 2004].'+\\\n",
    "                  ' Because malicious traffic occurs only after a DDoS attack has begun, there is limited time to'+\\\n",
    "                  ' prevent damage. In practice, more dynamic defense systems can be deployed for increased '+\\\n",
    "                  'resilience to DDoS, with increased cost'\n",
    "\n",
    "\n",
    "result = embed_post(paragraph_input)\n",
    "\n",
    "# jprint(result[1])\n",
    "print(len(result))\n",
    "print_completion_time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Construct training rows"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing week: 1. Reading posts csv file.\n",
      "Processing vulnerability number: 1\n",
      "Appendded new training data row. Training data shape: (1, 4)\n",
      "Appendded new training data row. Training data shape: (2, 4)\n",
      "Appendded new training data row. Training data shape: (3, 4)\n",
      "Appendded new training data row. Training data shape: (4, 4)\n",
      "Appendded new training data row. Training data shape: (5, 4)\n",
      "Processing vulnerability number: 2\n",
      "Appendded new training data row. Training data shape: (1, 4)\n",
      "Appendded new training data row. Training data shape: (2, 4)\n",
      "Appendded new training data row. Training data shape: (3, 4)\n",
      "Appendded new training data row. Training data shape: (4, 4)\n",
      "Appendded new training data row. Training data shape: (5, 4)\n",
      "Processing vulnerability number: 3\n",
      "Appendded new training data row. Training data shape: (1, 4)\n",
      "Appendded new training data row. Training data shape: (2, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/filipy/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/ubuntu/filipy/lib/python3.6/site-packages/bert_serving/client/__init__.py:299: UserWarning: some of your sentences have more tokens than \"max_seq_len=25\" set on the server, as consequence you may get less-accurate or truncated embeddings.\n",
      "here is what you can do:\n",
      "- disable the length-check by create a new \"BertClient(check_length=False)\" when you do not want to display this warning\n",
      "- or, start a new server with a larger \"max_seq_len\"\n",
      "  '- or, start a new server with a larger \"max_seq_len\"' % self.length_limit)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-75-ce4122ca0ca1>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m                 \u001B[0mpost_texts\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpost_text\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m                 \u001B[0membedded_text\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0membed_post\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpost_text\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m             \u001B[0mdata_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'0'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mpost_texts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membedded_text\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvul_target\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvul_onehot\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-74-e087837fa220>\u001B[0m in \u001B[0;36membed_post\u001B[0;34m(post_text)\u001B[0m\n\u001B[1;32m    175\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    176\u001B[0m     \u001B[0;31m# result = bc.encode(sentences, show_tokens=True)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 177\u001B[0;31m     \u001B[0mencoded_sentences\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msentences\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshow_tokens\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    178\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mencoded_sentences\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/filipy/lib/python3.6/site-packages/bert_serving/client/__init__.py\u001B[0m in \u001B[0;36marg_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    204\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreceiver\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetsockopt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzmq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRCVTIMEO\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    205\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 206\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    207\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mzmq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merror\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAgain\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0m_e\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    208\u001B[0m                 t_e = TimeoutError(\n",
      "\u001B[0;32m~/filipy/lib/python3.6/site-packages/bert_serving/client/__init__.py\u001B[0m in \u001B[0;36mencode\u001B[0;34m(self, texts, blocking, is_tokenized, show_tokens)\u001B[0m\n\u001B[1;32m    302\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mblocking\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    303\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 304\u001B[0;31m         \u001B[0mr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_recv_ndarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreq_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    305\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoken_info_available\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mshow_tokens\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    306\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokens\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/filipy/lib/python3.6/site-packages/bert_serving/client/__init__.py\u001B[0m in \u001B[0;36m_recv_ndarray\u001B[0;34m(self, wait_for_req_id)\u001B[0m\n\u001B[1;32m    168\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    169\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_recv_ndarray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwait_for_req_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 170\u001B[0;31m         \u001B[0mrequest_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_recv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwait_for_req_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    171\u001B[0m         \u001B[0marr_info\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marr_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjsonapi\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrombuffer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_buffer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr_val\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr_info\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'dtype'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/filipy/lib/python3.6/site-packages/bert_serving/client/__init__.py\u001B[0m in \u001B[0;36m_recv\u001B[0;34m(self, wait_for_req_id)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m                 \u001B[0;31m# receive a response\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 153\u001B[0;31m                 \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreceiver\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_multipart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    154\u001B[0m                 \u001B[0mrequest_id\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/filipy/lib/python3.6/site-packages/zmq/sugar/socket.py\u001B[0m in \u001B[0;36mrecv_multipart\u001B[0;34m(self, flags, copy, track)\u001B[0m\n\u001B[1;32m    473\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0many\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreasons\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m~\u001B[0m\u001B[0mSocket\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv\u001B[0m\u001B[0;31m`\u001B[0m \u001B[0mmight\u001B[0m \u001B[0mfail\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    474\u001B[0m         \"\"\"\n\u001B[0;32m--> 475\u001B[0;31m         \u001B[0mparts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrack\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrack\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    476\u001B[0m         \u001B[0;31m# have first part already, only loop while more to receive\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    477\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetsockopt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzmq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRCVMORE\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mzmq/backend/cython/socket.pyx\u001B[0m in \u001B[0;36mzmq.backend.cython.socket.Socket.recv\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mzmq/backend/cython/socket.pyx\u001B[0m in \u001B[0;36mzmq.backend.cython.socket.Socket.recv\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mzmq/backend/cython/socket.pyx\u001B[0m in \u001B[0;36mzmq.backend.cython.socket._recv_copy\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m~/filipy/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001B[0m in \u001B[0;36mzmq.backend.cython.checkrc._check_rc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "number_weeks = 53\n",
    "vulnerabiliies_per_week = 10\n",
    "rows_per_vulnerability = 5\n",
    "posts_per_row = 30\n",
    "\n",
    "RANDOMNESS_SEED = 156487\n",
    "output_file = '/datadrive/train-data/series1/train_data1.csv'\n",
    "\n",
    "#\n",
    "column_names = ['raw_text', 'encoded_text', 'raw_target', 'encoded_target']\n",
    "training_data = pd.DataFrame(columns=column_names)\n",
    "\n",
    "training_data.to_csv(path_or_buf=output_file, sep=';', header=True, index=False, mode='w+')\n",
    "\n",
    "\n",
    "for i in range(1, number_weeks + 1):\n",
    "\n",
    "    print(\"Now processing week: \" + str(i) + '. Reading posts csv file.')\n",
    "\n",
    "    posts = pd.read_csv(filepath_or_buffer=('/datadrive/train-data/posts_weeks/2016_posts_week_'+str(i)+'.csv') , sep=';', header=0)\n",
    "\n",
    "    posts = posts.dropna(subset=['week_no'])\n",
    "    posts = posts.astype({'week_no': 'int32'})\n",
    "\n",
    "    # There are no vulnerabilities that were published in week 1 (?)\n",
    "    if i == 1:\n",
    "        week_no = 2\n",
    "    else:\n",
    "        week_no = i\n",
    "\n",
    "    number_vulnerabilities = 0\n",
    "    for vulnerability in df_cve[df_cve['week_no'] == week_no].sample(frac=1, random_state=RANDOMNESS_SEED).iterrows():\n",
    "        number_vulnerabilities += 1\n",
    "        if number_vulnerabilities > vulnerabiliies_per_week:\n",
    "            break\n",
    "\n",
    "        print(\"Processing vulnerability number: \" + str(number_vulnerabilities))\n",
    "\n",
    "        for j in range(rows_per_vulnerability):\n",
    "\n",
    "            vul_target = vulnerability[1]['vul-target']\n",
    "            vul_onehot = vulnerability[1]['one-hot']\n",
    "\n",
    "            post_texts = []\n",
    "            embedded_text = []\n",
    "\n",
    "            for k in range(posts_per_row):\n",
    "\n",
    "                random_post = posts.sample()\n",
    "\n",
    "                post_text = random_post['Content'].values[0]\n",
    "\n",
    "                post_texts.append(post_text)\n",
    "                embedded_text.append(embed_post(post_text))\n",
    "\n",
    "            data_list = {'0': [post_texts, embedded_text, vul_target, vul_onehot]}\n",
    "            data_row = pd.DataFrame.from_dict(data_list, orient='index', columns=column_names)\n",
    "\n",
    "\n",
    "            training_data = training_data.append(data_row, ignore_index=True)\n",
    "\n",
    "            print(\"Appendded new training data row. Training data shape: \" + str(training_data.shape))\n",
    "\n",
    "        print('Writing out data to file.')\n",
    "        training_data.to_csv(path_or_buf=output_file, sep=';', header=False, index=False, mode='a')\n",
    "        training_data = pd.DataFrame(columns=column_names)\n",
    "\n",
    "print(training_data)\n",
    "\n",
    "print_completion_time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write out training data to file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed on: 2020-06-03 23:05:04.546122\n"
     ]
    }
   ],
   "source": [
    "training_data.to_csv(path_or_buf='/datadrive/train-data/series1/train_data1.csv', sep=';', header=True, index=False, mode='w+')\n",
    "\n",
    "print_completion_time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}