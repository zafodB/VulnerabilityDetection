import os

import keras.backend.tensorflow_backend as tfback
import pandas as pd
import tensorflow as tf
# from tensorflow.keras.layers import LSTM
# from tensorflow.keras.layers.convolutional import Conv1D, MaxPooling1D
from tensorflow.keras import Input, Model
from tensorflow.keras.layers import Dense, Lambda, Permute, LSTM, Conv1D, MaxPooling1D, Concatenate
# from tensorflow.keras.layers.merge import Concatenate
from tensorflow.keras.optimizers import Adam
import numpy as np


def initial_setup():

    # Setup path for Graphviz plotting tool
    os.environ["PATH"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'

    # some random Keras bug as per: https://github.com/keras-team/keras/issues/13684
    def _get_available_gpus():
        """Get a list of available gpu devices (formatted as strings).

        # Returns
            A list of available GPU devices.
        """
        global _LOCAL_DEVICES
        if tfback._LOCAL_DEVICES is None:
            devices = tf.config.list_logical_devices()
            tfback._LOCAL_DEVICES = [x.name for x in devices]
        return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]
    tfback._get_available_gpus = _get_available_gpus
    tfback._get_available_gpus()


def load_numpy_data(numpy_file_location: str):

    file_location = os.path.split(numpy_file_location)[-1]

    file_location = os.path.join('D:/Downloads/data/numpys', file_location)

    # print(file_location)
    return np.load(file=file_location)


def prepare_target_vector(input):
    return np.array(input)[np.newaxis]


def load_data(data_location: str) -> tf.data.Dataset:
    df = pd.read_csv(filepath_or_buffer=data_location, delimiter=';', header=0, converters={'encoded_target': eval})

    df['encoded_text_array'] = df['encoded_text'].apply(lambda x: load_numpy_data(x))

    target = df.pop(item='encoded_target')
    target = target.apply(lambda x: prepare_target_vector(x))

    print(target.head(5))
    print('Target dtypes: ' + str(type(target[1])))
    print('Target shape: ' + str(target[1].shape))
    print('Target length: ' + str(len(target[1])))

    df.pop(item='raw_text')
    df.pop(item='raw_target')
    df.pop(item='encoded_text')

    print(df.dtypes)

    dataset = tf.data.Dataset.from_tensor_slices(([value[0] for value in df.values], [value[0] for value in target.values]))

    print(dataset.element_spec)

    batched_set = dataset.batch(1)
    print(batched_set.element_spec)
    return batched_set


initial_setup()

print("hello there")

# sys.exit(0)

days = 7
posts_per_day = 2
embedding_length = 768
max_words_per_post = 375
target_vector_length = 50

shared_post_conv = Conv1D(filters=40, kernel_size=4, strides=1)
shared_permute = Permute((2,1))
shared_post_maxpool = MaxPooling1D(pool_size=10, strides=5, data_format='channels_first')

shared_day_conv = Conv1D(filters=40, kernel_size=1, strides=1)
shared_day_maxpool = MaxPooling1D(pool_size=5, strides=3, data_format='channels_first')

input = Input(shape=(days, posts_per_day, max_words_per_post, embedding_length))


day_outputs = []

for i in range(days):
    day = Lambda(lambda x: x[:, i, :, :, :])(input)

    post_outputs = []

    for j in range(posts_per_day):
        out = Lambda(lambda x: x[:, j, :, :])(day)

        post_x = (shared_post_conv)(out)
        post_x = (shared_permute)(post_x)
        post_x = (shared_post_maxpool)(post_x)
        post_outputs.append(post_x)

    day_x = Concatenate()(post_outputs)
    day_x = (shared_day_conv)(day_x)
    day_x = (shared_day_maxpool)(day_x)
    day_outputs.append(day_x)

week_overview = Concatenate()(day_outputs)

output_x = LSTM(units=50)(week_overview)

'''
activation='sigmoid' is important here because of the multi-label classification problem.
'''
output_x = Dense(units=target_vector_length, activation='sigmoid')(output_x)
model = Model(inputs=input, outputs=output_x)

'''
loss='binary_crossentropy' is important here because of the multi-label classification problem.

Check here: https://stackoverflow.com/questions/44164749/how-does-keras-handle-multilabel-classification
and here: https://towardsdatascience.com/multi-label-image-classification-with-neural-network-keras-ddc1ab1afede
'''
model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy')

# print(model.summary())
# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

train_dataset = load_data('D:/Downloads/data/train_data1.csv')

model.fit(train_dataset, epochs=2)
